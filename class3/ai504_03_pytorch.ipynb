{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1vC0N3Obk4HZJk9JOG7fKgYE10YYlCqsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: PyTorch, Logistic Regression and MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
    "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
    "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n",
    "\n",
    "If you have any questions, feel free to ask\n",
    "- For additional questions, post questions in classum or send emails to jihoontack@kaist.ac.kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intuitive and concise code\n",
    "- Define by Run method (Tensorflow is Define and Run method)\n",
    "- High compatibility with Numpy (almost one-to-one mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prelim: Load packages & GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize current GPU usages in your server\n",
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu by number \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the version of PyTorch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
    "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
    "**Almost the same with Numpy array**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch and Numpy shares almost identical grammer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**We will show some examples of:**\n",
    "- Same operation with identical grammer\n",
    "- Same operation with different grammer\n",
    "- Different operation with same grammer\n",
    "\n",
    "**We will not handle all examples in this class :(**\n",
    "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First! Define Numpy array and PyTorch tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array_1 = np.array([1, 2, 3, 4])\n",
    "np_array_2 = np.array([5, 6, 7, 8])\n",
    "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
    "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
    "\n",
    "print (np_array_1)\n",
    "print (np_array_2)\n",
    "print (torch_tensor_1)\n",
    "print (torch_tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Same operations with identical grammer**\n",
    "\n",
    "Example) Get the shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "print (np_array_1.shape)\n",
    "\n",
    "# torch\n",
    "print (torch_tensor_1.shape)\n",
    "print (torch_tensor_1.size()) # size() and shape operation is identical in torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Same operations with different grammer**\n",
    "\n",
    "Example 1) Concatenate two tensors\n",
    "- numpy use `np.concatenate`\n",
    "- torch use `torch.cat`\n",
    "- IMPORTANT: axis (numpy) and dim (torch) is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n",
    "print ('----numpy----')\n",
    "print (np_concate)\n",
    "\n",
    "# torch\n",
    "torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
    "print ('----torch----')\n",
    "print (torch_concate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2) reshape the tensor shape\n",
    "- numpy use `X.reshape`\n",
    "- torch use `X.view`\n",
    "- IMPORTANT: axis (numpy) and dim (torch) is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "np_reshaped = np_concate.reshape(4, 2)\n",
    "print ('----numpy----')\n",
    "print (np_reshaped)\n",
    "print (np_reshaped.shape)\n",
    "\n",
    "# torch\n",
    "torch_reshaped = torch_concate.view(4, 2)\n",
    "print ('----torch----')\n",
    "print (torch_reshaped)\n",
    "print (torch_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Different operations with same grammer (Confusing operations)**\n",
    "\n",
    "Example) manipulation tensors\n",
    "- Same grammer `repeat`  has different operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "x_repeat = x.repeat(2)\n",
    "\n",
    "print ('----numpy----')\n",
    "print (x)\n",
    "print (x_repeat)\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_repeat = x.repeat(2)\n",
    "\n",
    "print ('----torch----')\n",
    "print (x)\n",
    "print (x_repeat)\n",
    "\n",
    "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
    "x_repeat = x.view(3, 1).repeat(1, 2).view(-1)\n",
    "print (x_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar manipulation operation: stack & repeat\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_repeat = x.repeat(4)\n",
    "x_stack = torch.stack([x, x, x, x])\n",
    "\n",
    "print (x_repeat)\n",
    "print (x_stack)\n",
    "print (x_repeat.view(4, 3)) # reshape x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor operations under GPU utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning frameworks utilize GPUs to accelarate computations.\n",
    "\n",
    "In this section, we will learn **how to utilize GPU** in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())  # Is GPU accessible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3)\n",
    "b = torch.randn(100, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload a and b to GPU\n",
    "a = a.to('cuda')\n",
    "b = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central to all neural networks in PyTorch is the `autograd` package. \n",
    "\n",
    "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
    "\n",
    "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 3\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = z.mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.retain_grad()\n",
    "z.retain_grad()\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n",
    "![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n",
    "![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n",
    "![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient inference (testing) with torch.no_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
    "\n",
    "Situation: when **gradient calculation is not required** e.g., inference\\\n",
    "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.ones(2, 2, requires_grad=True)\n",
    "    y = x + 2\n",
    "    z = y * y * 3\n",
    "    out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-defined modules (subset of models) in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "\n",
    "print (X)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dim 3, output dim 1\n",
    "linear_fn = nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_fn  # WX + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = linear_fn(X)\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.sum()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use other types of `nn.Module` in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d\n",
    "nn.RNNCell\n",
    "nn.LSTMCell\n",
    "nn.GRUCell\n",
    "nn.Transformer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we design a customized model (neural network)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x) # Activation function\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is activation function?**\n",
    "- They make non-linearity for deep neural networks\n",
    "- Therefore, deep neural networks can approximate complex functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1dxJJUOzYykRfW2q3my2Qtg82RsjptIx4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sigmoid\n",
    "nn.ReLU\n",
    "nn.LeakyReLU\n",
    "nn.Tanh;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1kdig6RLSCvYJNqarbb8gviYsnxZfSkYQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is MNIST & How to do multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
    "\n",
    "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
    "\n",
    "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "# mini batch size\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model (we will use one layer classifier first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1Xe4J88NglbuASnfYJYI7ISqA1c1rcs5P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class\n",
    "# This model has one hidden layer\n",
    "class Multinomial_logistic_regression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Multinomial_logistic_regression, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model\n",
    "model = Multinomial_logistic_regression(784, 10)  # init(784, 10)\n",
    "# input dim: 784  / output dim: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to GPU\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
    "\n",
    "PyTorch optimizer is about **which optimization methods to use for training**\n",
    "\n",
    "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer define\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function define (we use cross-entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
    "        # upload to gpu\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        print (images.shape)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)  # forwardI(images): get prediction\n",
    "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # automatic gradient calculation (autograd)\n",
    "        optimizer.step()  # update model parameter with requires_grad=True \n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model: MLP (multi-layer-perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous model used multinomial logistic regression (one linear layer)\\\n",
    "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model with multi layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model\n",
    "model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n",
    "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
    "\n",
    "# Upload model to GPU\n",
    "model = model.to('cuda')\n",
    "\n",
    "# Loss function define (we use cross-entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
    "        # upload to gpu\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)  # forwardI(images): get prediction\n",
    "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # automatic gradient calculation (autograd)\n",
    "        optimizer.step()  # update model parameter with requires_grad=True \n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the following options to obtain better accuracy!! (try it by your-self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Model configurations: \n",
    "- size of hidden layer units\n",
    "- number of layers\n",
    "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
    "\n",
    "#### (2) Optimization configurations\n",
    "- learning rate\n",
    "- epoch\n",
    "- type of optimizer\n",
    "- momentem hyperparameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
