{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1vC0N3Obk4HZJk9JOG7fKgYE10YYlCqsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Generative adversarial network (GAN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will cover basic concepts of GAN & implement vanilla GAN \\[[Goodfellow et al., NIPS 2014](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)\\]\n",
    "- We will give basic skeletone code which include (1) training structure (2) sample visualization (3) FID evaluation\n",
    "- You should implement (1) ***generator & discriminator architecture*** (2) ***noise sampling***  (3) ***GAN loss*** \n",
    "- Additionally, will give you [DCGAN](https://arxiv.org/abs/1511.06434) (basic GAN architecture) code that you can enjoy by your-self \n",
    "\n",
    "If you have any questions, feel free to ask\n",
    "- For additional questions, send emails to jihoontack@kaist.ac.kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Prelim step 1: Load packages & GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize current GPU usages in your server\n",
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu by number \n",
    "import os\n",
    "import random\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import imageio #### install with \"pip install imageio\"\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders\n",
    "if not os.path.exists('./checkpoint'):\n",
    "    os.mkdir('./checkpoint')\n",
    "    \n",
    "if not os.path.exists('./dataset'):\n",
    "    os.mkdir('./dataset')\n",
    "    \n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')\n",
    "    \n",
    "if not os.path.exists('./img/real'):\n",
    "    os.mkdir('./img/real')\n",
    "\n",
    "if not os.path.exists('./img/fake'):\n",
    "    os.mkdir('./img/fake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Prelim step 2: Define visualization & image saving code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first image from the torch tensor\n",
    "def vis_image(image):\n",
    "    plt.imshow(image[0].detach().cpu().numpy(),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif(training_progress_images, images):\n",
    "    '''\n",
    "        training_progress_images: list of training images generated each iteration\n",
    "        images: image that is generated in this iteration\n",
    "    '''\n",
    "    img_grid = make_grid(images.data)\n",
    "    img_grid = np.transpose(img_grid.detach().cpu().numpy(), (1, 2, 0))\n",
    "    img_grid = 255. * img_grid \n",
    "    img_grid = img_grid.astype(np.uint8)\n",
    "    training_progress_images.append(img_grid)\n",
    "    imageio.mimsave('./img/training_progress.gif', training_progress_images)\n",
    "    return training_progress_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize gif file\n",
    "def vis_gif(training_progress_images):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ims = []\n",
    "    for i in range(len(training_progress_images)):\n",
    "        im = plt.imshow(training_progress_images[i], animated=True)\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "    \n",
    "    html = ani.to_html5_video()\n",
    "    HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize gif file\n",
    "def plot_gif(training_progress_images, plot_length=10):\n",
    "    plt.close()\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    total_len = len(training_progress_images)\n",
    "    for i in range(plot_length):\n",
    "        im = plt.imshow(training_progress_images[int(total_len/plot_length)*i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_list(dataset, real):\n",
    "    if real:\n",
    "        base_path = './img/real'\n",
    "    else:\n",
    "        base_path = './img/fake'\n",
    "    \n",
    "    dataset_path = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        save_path =  f'{base_path}/image_{i}.png'\n",
    "        dataset_path.append(save_path)\n",
    "        vutils.save_image(dataset[i], save_path)\n",
    "    \n",
    "    return base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Prelim step 3: Load dataset, define dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1kdig6RLSCvYJNqarbb8gviYsnxZfSkYQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this class we will use **MNIST** (or you can use **Fashion-MNIST**) due to the time constraint :( \\\n",
    "You can practice with CIFAR-10 by your-self since dataset is already implemented inside PyTorch!\n",
    "- Simply use `dataset=dset.CIFAR10(.)` function in PyTorch.\n",
    "- If you are using CIFAR dataset, please note that the resolution is different to MNIST and should change model input dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=\"./dataset\", download=True,\n",
    "                                   transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                ]))\n",
    "# If you want to download FMNIST use dset.FashionMNIST\n",
    "# dataset = dset.FashionMNIST(.)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define your generator & discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Define generator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            #########################\n",
    "            # Define your own generator #\n",
    "            #########################\n",
    "            \n",
    "            \n",
    "            #########################\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        #####################################\n",
    "        # Change the shape of output if necessary #\n",
    "        \n",
    "        #####################################\n",
    "        \n",
    "        output = self.main(input)\n",
    "        \n",
    "        #####################################\n",
    "        # Change the shape of output if necessary #\n",
    "        \n",
    "        #####################################\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define discriminator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            ############################\n",
    "            # Define your own discriminator #\n",
    "            ############################\n",
    "            \n",
    "            \n",
    "            ############################\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        #####################################\n",
    "        # Change the shape of output if necessary #\n",
    "    \n",
    "        #####################################\n",
    "        \n",
    "        output = self.main(input)\n",
    "        \n",
    "        #####################################\n",
    "        # Change the shape of output if necessary #\n",
    "        \n",
    "        #####################################\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Upload on GPU, define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator().cuda()\n",
    "netD = Discriminator().cuda()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Noise sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implement here ####\n",
    "noise = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement GAN by filling out the following blankes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = ?\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "n_epoch = 200\n",
    "training_progress_images_list = []\n",
    "for epoch in range(n_epoch):\n",
    "    for i, (data, _) in enumerate(dataloader):\n",
    "        ####################################################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) #\n",
    "        ###################################################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        data = data.cuda()\n",
    "        batch_size = data.size(0)\n",
    "        \n",
    "        label = ? # real label \n",
    "        output = ?\n",
    "        errD_real = ?\n",
    "\n",
    "        # train with fake\n",
    "        noise = ?\n",
    "        fake = ?\n",
    "        label = ? # fake label\n",
    "        output = ?\n",
    "        errD_fake = ?\n",
    "        \n",
    "        # Loss backward\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        ########################################\n",
    "        # (2) Update G network: maximize log(D(G(z))) #\n",
    "        ########################################\n",
    "        netG.zero_grad()\n",
    "        label = ? # fake labels are real for generator cost\n",
    "        output = ?\n",
    "        errG = ?\n",
    "\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "    print('[%d/%d] Loss_D: %.4f Loss_G: %.4f' \n",
    "              % (epoch, n_epoch, errD.item(), errG.item()))\n",
    "    \n",
    "    #save the output\n",
    "    fake = netG(fixed_noise)\n",
    "    training_progress_images_list = save_gif(training_progress_images_list, fake)  # Save fake image while training!\n",
    "    \n",
    "    # Check pointing for every epoch\n",
    "    torch.save(netG.state_dict(), './checkpoint/netG_epoch_%d.pth' % (epoch))\n",
    "    torch.save(netD.state_dict(), './checkpoint/netD_epoch_%d.pth' % (epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize/Plot your generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_gif(training_progress_images_list)\n",
    "plot_gif(training_progress_images_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate your model: Fréchet Inception Distance (FID) score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to evaluate the equality of your generated sample?\\\n",
    "Maybe **training loss...? No!**\n",
    "Papers have shown that training loss might not be the best metric!\n",
    "\n",
    "There are many evaluation metric that has been proposed and most famous metric is as follows: [**Inception score**](https://arxiv.org/abs/1606.03498), [**Fréchet Inception Distance**](https://arxiv.org/abs/1706.08500)\n",
    "\n",
    "In this course, we will handle **Fréchet Inception Distance (FID) score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. What is FID score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FID measures the distance between **real dataset** & **fake dataset** in **feature space of Inception** pretrained network.\\\n",
    "From the extracted features of real & fake dataset, we can compute mean & covariance of each features to calculate the **distance between distributions**.\n",
    "- For more explanation see this [article](https://medium.com/@jonathan_hui/gan-how-to-measure-gan-performance-64b988c47732) or [paper](https://arxiv.org/abs/1706.08500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation, we simply use the source code from github: https://github.com/mseitzer/pytorch-fid\n",
    "\n",
    "Please note that Inception network is **pretrained on ImageNet**, therefore the MNIST FID score might be unrealiable.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Load FID score function: code is from the github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1InzR1qylS3Air4IvpS9CoamqJ0r9bqQg' -O inception.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1AtTxnuasIaSTTmI9MI7k8ugY8KJ1cw3Y' -O fid_score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fid_score import calculate_fid_given_paths  # The code is downloaded from github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Evaluate your model (save samples!!)\n",
    "\n",
    "The Inception network's input resolution is 224 by 224, we upscale small resolution datasets (e.g., MNSIT, CIFAR) into same resolution.\n",
    "\n",
    "Please note that, we only save *50 samples in this lecture*, however in practice we use **full test dataset**: [reference](https://arxiv.org/abs/1807.04720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dset.MNIST(root=\"./dataset\", download=True, train=False,\n",
    "                                           transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                        ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=True, num_workers=2)\n",
    "\n",
    "for i, (data, _) in enumerate(dataloader):\n",
    "    real_dataset = data\n",
    "    break\n",
    "    \n",
    "noise = torch.randn(50, 100).cuda()\n",
    "fake_dataset = netG(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image_path_list = save_image_list(real_dataset, True)\n",
    "fake_image_path_list = save_image_list(fake_dataset, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Evaluate FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_fid_given_paths(paths, batch_size, cuda, dims)\n",
    "fid_value = calculate_fid_given_paths([real_image_path_list, fake_image_path_list],\n",
    "                                                          50, \n",
    "                                                          True,\n",
    "                                                          2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'FID score: {fid_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: DCGAN (try it by your-self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various modern architectures of GAN e.g., DCGAN, SNGAN, and also training methods e.g., WGAN, gradient penulty\n",
    "\n",
    "You can try the following architecture to improve the quality of generation!\n",
    "- **Note that this version is for 64 by 64 resolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 3 # number of channels, RGB\n",
    "nz = 100 # input noise dimension\n",
    "ngf = 64 # number of generator filters\n",
    "ndf = 64 #number of discriminator filters\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "PyTorch official DCGAN tutorial: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html \\\n",
    "github 1: https://github.com/Ksuryateja/DCGAN-CIFAR10-pytorch/blob/master/gan_cifar.py \\\n",
    "github 2: https://github.com/mseitzer/pytorch-fid \\\n",
    "FID score: https://github.com/mseitzer/pytorch-fid \\\n",
    "Inception score: https://github.com/sbarratt/inception-score-pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
